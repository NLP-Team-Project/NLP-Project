{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237c686e",
   "metadata": {},
   "source": [
    "# Predicting Program Languages\n",
    "\n",
    "For this project our group will be scraping, and using api requests to acquire repository data from Github and attempt to create an NLP model to predict the primary programming language of the repo based off the contents of the readme file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9dbe96",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "* Scrape repo names from Github, and use api requests to create a database of repos\n",
    "* Explore data to see what words are most common in each respective language's readmes\n",
    "* Build a classification model that predicts program languages used in each repo on Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b6d87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e24ca3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82262fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/goat/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/goat/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'github_token' from 'env' (/Users/goat/codeup-data-science/NLP-Project/env.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import function modules\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprepare\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01macquire\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01ma\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Import data science libraries & visualization libraries\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/codeup-data-science/NLP-Project/acquire.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Union, cast\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m github_token, github_username\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprepare\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'github_token' from 'env' (/Users/goat/codeup-data-science/NLP-Project/env.py)"
     ]
    }
   ],
   "source": [
    "# Import function modules\n",
    "import prepare as p\n",
    "import acquire as a\n",
    "\n",
    "\n",
    "# Import data science libraries & visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import nlp libraries and classification models\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9759a90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6d24b",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1563f91",
   "metadata": {},
   "source": [
    "| Column         | Column_type | Data_type| Description              |\n",
    "|----------------|-------------|----------|--------------------------|\n",
    "|repo            |Feature      |string    |Name of the repositiory.  |\n",
    "|language        |Target       |string    |Programming language used.|\n",
    "|readme_contents |Feature      |string    |Contents for every readme.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16c926",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f23ac7",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341a75d-e8b9-436a-b009-d41fe18f76e7",
   "metadata": {},
   "source": [
    "For data acquisition, the names of 100 pages worth of 'sports' repositories (1000 repos) were scraped using html requests. Then using api requests information such as language, name, and readme contents, was pulled from the repositories. This process was slow due to request limits so the data was cached into a csv once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('all_repos.csv').head(3)  # Read data stored in .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ec91f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b751bcb",
   "metadata": {},
   "source": [
    "## Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691eb711-4949-4c64-9276-762e6a0e4b18",
   "metadata": {},
   "source": [
    "For data cleaning, any language that wasn't in the top 4 was grouped into 'other'. The extra number of languages severy impacted model performance, so grouping them was helpful. The data was also cleaned, stemmed, and lemmatized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab949854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repo = a.acquire_repos()  # Pull and clean data stored in .csv file\n",
    "repo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2cb05-12ae-4699-bdc6-7535b047fb95",
   "metadata": {},
   "source": [
    "During the wrangling process, around 200 rows were dropped due to incorrect language (jupyter notebook), and missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d8446",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679cefa",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97111d6-f0fe-4a54-8032-eabacd0758d6",
   "metadata": {},
   "source": [
    "Before beggining exploration the data is split into train, val, test so that only the train data is explored on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa043c1-de73-4bef-aeb7-e20fc9dbebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = p.train_val_test(repo, 'language', stratify=True)  # Splits data and stratifies by target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b644d-432a-4285-a4b7-e98d2bfcfaca",
   "metadata": {},
   "source": [
    "Then, a dataframe of the total number of time each word appeared in each language is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e1e07-b04c-4e57-a4d9-f7ac48c70fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function to create a dataframe with the word counts of each word\n",
    "repo = p.word_counts(train, 'language', 'clean')\n",
    "repo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b776b-b340-48fa-8857-ad96079b9974",
   "metadata": {},
   "source": [
    "We will also calculate in how many documents each word appeared in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a60128-6ff8-4a47-a192-f04e49033a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_appearances = p.word_appearances(repo, train)  # Calculate the number of separate readmes that a word appeared in\n",
    "word_counts['total_appearances'] = total_appearances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1550a",
   "metadata": {},
   "source": [
    "### What are the most common words in READMEs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2d727",
   "metadata": {},
   "source": [
    "### Does the length of the README vary by programming language?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb13e6f",
   "metadata": {},
   "source": [
    "### Do different programming languages use a different number of unique words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e5758",
   "metadata": {},
   "source": [
    "### Are there any words that uniquely identify a programming language?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ab188",
   "metadata": {},
   "source": [
    "### EDA Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21890f43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249e2dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36740eb-ad7f-4b4e-8e12-9d3c2829b4db",
   "metadata": {},
   "source": [
    "Now we will create some models to try to predict the primary language of a repo based off the readme contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b33db-ee8f-4568-99dd-3c5eabbd4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe again\n",
    "repo = pd.read_csv('all_repos.csv')\n",
    "repo.language = p.top_languages(repo, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f55d3a",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711b4e5-e3e3-4a85-95e4-b7d230dfac3e",
   "metadata": {},
   "source": [
    "The first mode created is the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da689bf1-96d8-494f-8437-34ac9ec1acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline from the mode of the languages\n",
    "baseline = pd.DataFrame(train.language)\n",
    "baseline['baseline'] = baseline.language.value_counts().index[0]\n",
    "print(f'Baseline accuracy: {round((baseline.language == baseline.baseline).sum()/(len(baseline)),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e9d2b-4e3d-46f1-bd6e-24f4ee57b4d3",
   "metadata": {},
   "source": [
    "Baseline model only guesses 'other' since it is the most common 'language'. The baseline accuracy is only 43%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488ff55",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7deb2a-8a5e-418e-9802-785e793b9bc0",
   "metadata": {},
   "source": [
    "Using the word counts per language, a filter is created to eliminate words that appear very few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf29c2-832d-4bdb-bc9e-885f46e126c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo2 = p.cleanse(repo, 'readme_contents')\n",
    "all_words = p.word_counts(repo2, 'language', 'clean')  # Use word counts to create filter\n",
    "word_filter = list(all_words[all_words['all'] < 35].index)  # Create list to remove all words that appear less than 35 times total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b71529-b180-4578-ac0d-1c6213943c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = p.cleanse(repo, 'readme_contents', extra_words=word_filter)  # Clean data\n",
    "train, val, test = p.train_val_test(repo, 'language', stratify=True, print_shape=False)\n",
    "X_train_tfidf, y_train, X_val_tfidf, y_val, X_test_tfidf, y_test = p.preprocess(train, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d64f2b-b984-4b7c-996d-c1e6dc6e581d",
   "metadata": {},
   "source": [
    "Before modeling data is split into x and y and each word is turned into a feature so the models can properly use data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ff2b1-0d32-4632-b11c-2e74c69f2cfb",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8a361-2b81-404b-82d5-e821f3099cc0",
   "metadata": {},
   "source": [
    "XGB was the third best model. It is extremelly overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f50735-7b48-4efe-932b-3d19d6dac0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label ecoder and encode tager variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.fit_transform(y_val)\n",
    "\n",
    "# Create and train model object\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_tfidf, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf079b-9515-418a-9fc9-4063de9a7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model\n",
    "p.test_model(xgb, X_train_tfidf, y_train_encoded)\n",
    "p.test_model(xgb, X_val_tfidf, y_val_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b5963-549e-45d8-8b4d-7f45c4450747",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82529015-7774-4925-bb09-a76d2ca3173e",
   "metadata": {},
   "source": [
    "Linear regression performed the second best and it was less overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591e5ea-f6c1-4be6-ac72-0f824a5d1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model object\n",
    "lm = LogisticRegression(class_weight='balanced')\n",
    "lm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b298e5-c04b-40e0-840e-f13406e7aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model\n",
    "p.test_model(lm, X_train_tfidf, y_train)\n",
    "p.test_model(lm, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c8a76-35d7-46d6-aa85-c8e02991019f",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f2416-7ace-4c38-b018-91f3b5c9dc2e",
   "metadata": {},
   "source": [
    "The best model was random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20fbbe-a695-41d3-8057-881f6d94b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)  # Create model object\n",
    "rfc.fit(X_train_tfidf, y_train)  # Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f109d-83c6-4952-87eb-1e0291f9601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model\n",
    "p.test_model(rfc, X_train_tfidf, y_train)\n",
    "p.test_model(rfc, X_val_tfidf, y_val)\n",
    "p.test_model(rfc, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5dabd-73dc-4cfb-a7cb-8d8ced9dde7a",
   "metadata": {},
   "source": [
    "Random forest classifier was very overfit and validated at 67% accuracy and tested at 63% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31f0bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565e6a6",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd7f5c-1f01-414e-9070-48d69a34f8b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb00bd20-988c-47bd-80b5-879b8045d8c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff8e293-e11c-4a5c-b2ee-888e4a1388f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da163011-76bc-40dd-be4a-56e1ccc1e403",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb786d1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb9871",
   "metadata": {},
   "source": [
    "# Recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf38ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51b9b837",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9adfc",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021cda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "269bf706",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
